{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import pickle\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import numpy as np \n",
    "\n",
    "class ChoiceDataset(Dataset):\n",
    "    def __init__(self, data_path, data_file):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            data_file (string): name of data pickle file\n",
    "        \"\"\"\n",
    "        data = pickle.load(open(data_path + \"/\" + data_file, \"rb\"))\n",
    "        self.x = torch.Tensor(data[\"x\"])\n",
    "        self.x_names = data[\"x_names\"]\n",
    "        self.N = len(self.x)\n",
    "        \n",
    "        dic_attr = \\\n",
    "        {\"TRAIN\": [\"TRAIN_TT\", \"TRAIN_HE\", \"TRAIN_CO\"], \\\n",
    "         \"SM\": [\"SM_TT\", \"SM_HE\", \"SM_CO\", \"SM_SEATS\"],\\\n",
    "         \"CAR\": [\"CAR_TT\", \"CAR_CO\"]}\n",
    "        \n",
    "        self.x_dict = {}\n",
    "        for mode in dic_attr:\n",
    "            self.x_dict[mode] = {}\n",
    "            for attr in dic_attr[mode]:\n",
    "                self.x_dict[mode].update({attr: getAttribute(self.x, self.x_names, attr)})\n",
    "        \n",
    "        self.y = torch.LongTensor(data[\"y\"])-1 # N\n",
    "        \n",
    "        # Availability \n",
    "        self.av = torch.cat([torch.ones(self.N,2),torch.Tensor(data[\"car_av\"]).view(self.N,1)], dim=1) # (N,3) av for all modes \n",
    "        \n",
    "        # all z \n",
    "        self.z_all_names = data['z_names']\n",
    "        self.z_levels = data['z_levels']\n",
    "        self.z_all = torch.Tensor(data['z']) # N,D socio-demo variables\n",
    "\n",
    "        # select z\n",
    "        self.z_names = [\"MALE_1\", \"AGE_1\", \"AGE_2\", \"AGE_3\", \"AGE_4\", \\\n",
    "               \"INCOME_1\", \"INCOME_2\", \"INCOME_3\", \"FIRST_1\", \"WHO_1\", \"WHO_2\", \\\n",
    "               \"PURPOSE_1\", \"PURPOSE_2\", \"PURPOSE_3\", \"LUGGAGE_1\", \"LUGGAGE_2\", \"GA_1\"]\n",
    "        self.z = selectZ(self.z_all, self.z_names, self.z_all_names)\n",
    "        \n",
    "        _, self.D = self.z.size() # z size = (N,D)\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.N\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        Get the sample given its idx in the list \n",
    "        '''\n",
    "        x = {}\n",
    "        for mode in self.x_dict:\n",
    "            x[mode] = {}\n",
    "            for name in self.x_dict[mode]:\n",
    "                x[mode][name] = self.x_dict[mode][name][idx]\n",
    "        return {\"x\": x, \"y\": self.y[idx], \"z\":self.z[idx], \"av\": self.av[idx]}\n",
    "    \n",
    "def getAttribute(x, x_names, name):\n",
    "    return x[:,x_names.index(name)]\n",
    "    \n",
    "def selectZ(z,z_selected, z_names):\n",
    "    ind = []\n",
    "    for var in z_selected:\n",
    "        ind.append(z_names.index(var))\n",
    "    return z[:,np.array(ind).astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import ChoiceDataset\n",
    "data_test = \"test.pkl\"\n",
    "ds_test = ChoiceDataset('/mnt/md0/TasteNet-MNL/swissmetro/data/', data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 ... 1 0 1]\n",
      "1604\n",
      "{'x': {'TRAIN': {'TRAIN_TT': tensor([1.1600, 2.7200, 1.4300, 2.0100]), 'TRAIN_HE': tensor([0.3000, 0.6000, 0.6000, 0.6000]), 'TRAIN_CO': tensor([0.3500, 1.3400, 0.7500, 1.6600])}, 'SM': {'SM_TT': tensor([0.7300, 1.3500, 0.9800, 1.6200]), 'SM_HE': tensor([0.2000, 0.2000, 0.1000, 0.3000]), 'SM_CO': tensor([0.4500, 1.4600, 0.9000, 2.1000]), 'SM_SEATS': tensor([0., 0., 0., 0.])}, 'CAR': {'CAR_TT': tensor([0.0000, 1.6800, 1.3000, 1.4400]), 'CAR_CO': tensor([0.0000, 1.2800, 0.8400, 1.3600])}}, 'y': tensor([0, 2, 1, 2]), 'z': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.],\n",
      "        [1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0.],\n",
      "        [1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0.],\n",
      "        [1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0.]]), 'av': tensor([[1., 1., 0.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])}\n"
     ]
    }
   ],
   "source": [
    "data = pickle.load(open('/mnt/md0/TasteNet-MNL/swissmetro/data/' + data_test, \"rb\"))\n",
    "print(data[\"car_av\"])\n",
    "x = torch.Tensor(data[\"x\"])\n",
    "N = len(x)\n",
    "print(N)\n",
    "print(ds_test[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test.z.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open json file\n",
    "import json\n",
    "with open('/mnt/md0/TasteNet-MNL/sg/RandomSplitData1_PassengerType_TripEncoded.json') as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Import /mnt/md0/TasteNet-MNL/sg/RandomSplitData1_PassengerType_TripEncoded.json as df\n",
    "df = pd.read_json('/mnt/md0/TasteNet-MNL/sg/RandomSplitData1_PassengerType_TripEncoded.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Jid', 'first_stop', 'last_stop', 'Time', 'CommNodeOrigin',\n",
       "       'CommNodeDest', 'NoRoutes', 'routes_summary', 'Mode_Type', 'IVTT',\n",
       "       'NoT', 'PT_dst', 'PT_fare', 'WalkTime', 'PT_route_choice',\n",
       "       'choice_index', 'OD', 'passengerType', 'Adult', 'Student', 'Senior',\n",
       "       'ODEncoded', 'TransferEncoded', 'PassengerTypeEncoded'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "df['choice_index'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1271/1820996710.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.z_all = torch.stack([torch.tensor(elem) for elem in df['PassengerTypeEncoded'].apply(lambda x: torch.Tensor(x[0])).values])# N,D socio-demo variables\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ChoiceDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        # 1. Get the max number of routes\n",
    "        self.maxNoRoutes = df['NoRoutes'].max()\n",
    "\n",
    "        # 2. Iterate each row (in vectorized manner). Each row's NoRoutes is the number of routes. Beyond that, all zero\n",
    "        x = np.zeros((len(df), self.maxNoRoutes, 4))\n",
    "        for i in range(len(df)):\n",
    "            for j in range(df['NoRoutes'].iloc[i]):\n",
    "                x[i, j, 0] = df['IVTT'].iloc[i][j]\n",
    "                x[i, j, 1] = df['PT_fare'].iloc[i][j]\n",
    "                x[i, j, 2] = df['WalkTime'].iloc[i][j]\n",
    "                x[i, j, 3] = df['NoT'].iloc[i][j]\n",
    "        self.x = torch.Tensor(x.reshape(len(df), 4*self.maxNoRoutes))\n",
    "        # 3. Create names IVTT_1, PT_fare_1. WalkTime_1, NoT_1, IVTT_2, ... IVTT_max_routes, PT_fare_max_routes, WalkTime_max_routes, NoT_max_routes\n",
    "        self.x_names = [[f'IVTT{i}', f'PT_fare{i}', f'WalkTime{i}', f'NoT{i}'] for i in range(0, self.maxNoRoutes)]\n",
    "        # Flatten list of lists\n",
    "        self.x_names = [item for sublist in self.x_names for item in sublist]\n",
    "        self.N = len(df)\n",
    "        \n",
    "        # Create dic_attr depending on df['NoRoutes']\n",
    "        dic_attr = {}\n",
    "        for i in range(0, self.maxNoRoutes):\n",
    "            dic_attr.update({str(i): [f'IVTT{i}', f'PT_fare{i}', f'WalkTime{i}', f'NoT{i}']})\n",
    "\n",
    "        self.x_dict = {}\n",
    "        for mode in dic_attr:\n",
    "            self.x_dict[mode] = {}\n",
    "            for attr in dic_attr[mode]:\n",
    "                self.x_dict[mode].update({attr: getAttribute(self.x, self.x_names, attr)})\n",
    "\n",
    "        self.y = torch.LongTensor(df['choice_index'].values)  # N\n",
    "\n",
    "        # Availability\n",
    "        NoRoutes = torch.Tensor(df['NoRoutes'].values)\n",
    "        N = len(NoRoutes)\n",
    "        NoRoutes = NoRoutes.unsqueeze(1)\n",
    "        av_ones = torch.ones(N, self.maxNoRoutes*4)\n",
    "\n",
    "        # Create a mask indicating where to place zeros based on `NoRoutes` values\n",
    "        mask = torch.arange(self.maxNoRoutes*4).unsqueeze(0) < NoRoutes*4\n",
    "\n",
    "        # Apply the mask to the `av_ones` tensor to set zeros where needed\n",
    "        self.av = av_ones * mask.float()\n",
    "\n",
    "        # all z \n",
    "        # Rename df columns 'Adult', 'Student', 'Senior' to 'CARDTYPE_0', 'CARDTYPE_1', 'CARDTYPE_2'\n",
    "        df.rename(columns={'Adult': 'CARDTYPE_0', 'Student': 'CARDTYPE_1', 'Senior': 'CARDTYPE_2'}, inplace=True)\n",
    "        self.z_all_names = ['CARDTYPE_0', 'CARDTYPE_1', 'CARDTYPE_2']\n",
    "        self.z_levels = OrderedDict([('CARDTYPE_0', 3)])\n",
    "        self.z_all = torch.stack([torch.tensor(elem) for elem in df['PassengerTypeEncoded'].apply(lambda x: torch.Tensor(x[0])).values])# N,D socio-demo variables\n",
    "\n",
    "\n",
    "        # select z\n",
    "        self.z_names = [\"CARDTYPE_1\", \"CARDTYPE_2\"]\n",
    "        self.z = selectZ(self.z_all, self.z_names, self.z_all_names)\n",
    "        _, self.D = self.z.size()  # z size = (N,D)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.N\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = {}\n",
    "        for mode in self.x_dict:\n",
    "            x[mode] = {}\n",
    "            for name in self.x_dict[mode]:\n",
    "                x[mode][name] = self.x_dict[mode][name][idx]\n",
    "        return {\"x\": x, \"y\": self.y[idx], \"z\": self.z[idx], \"av\": self.av[idx]}\n",
    "\n",
    "\n",
    "def getAttribute(x, x_names, name):\n",
    "    return x[:, x_names.index(name)]\n",
    "\n",
    "\n",
    "def selectZ(z, z_selected, z_names):\n",
    "    ind = []\n",
    "    for var in z_selected:\n",
    "        ind.append(z_names.index(var))\n",
    "    return z[:, ind]\n",
    "\n",
    "\n",
    "# Create the ChoiceDataset object\n",
    "dataset = ChoiceDataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'x': {'0': {'IVTT0': tensor(3242.), 'PT_fare0': tensor(1.3800), 'WalkTime0': tensor(318.), 'NoT0': tensor(1.)}, '1': {'IVTT1': tensor(3708.), 'PT_fare1': tensor(1.3800), 'WalkTime1': tensor(318.), 'NoT1': tensor(1.)}, '2': {'IVTT2': tensor(3829.), 'PT_fare2': tensor(1.3800), 'WalkTime2': tensor(318.), 'NoT2': tensor(1.)}, '3': {'IVTT3': tensor(3347.), 'PT_fare3': tensor(1.4400), 'WalkTime3': tensor(339.), 'NoT3': tensor(1.)}, '4': {'IVTT4': tensor(3583.), 'PT_fare4': tensor(1.3800), 'WalkTime4': tensor(318.), 'NoT4': tensor(1.)}, '5': {'IVTT5': tensor(1184.), 'PT_fare5': tensor(1.3800), 'WalkTime5': tensor(374.), 'NoT5': tensor(0.)}, '6': {'IVTT6': tensor(2437.), 'PT_fare6': tensor(1.3800), 'WalkTime6': tensor(506.), 'NoT6': tensor(1.)}, '7': {'IVTT7': tensor(2064.), 'PT_fare7': tensor(1.3800), 'WalkTime7': tensor(506.), 'NoT7': tensor(1.)}, '8': {'IVTT8': tensor(2315.), 'PT_fare8': tensor(1.3800), 'WalkTime8': tensor(506.), 'NoT8': tensor(1.)}, '9': {'IVTT9': tensor(2295.), 'PT_fare9': tensor(1.3800), 'WalkTime9': tensor(506.), 'NoT9': tensor(1.)}, '10': {'IVTT10': tensor(0.), 'PT_fare10': tensor(0.), 'WalkTime10': tensor(0.), 'NoT10': tensor(0.)}, '11': {'IVTT11': tensor(0.), 'PT_fare11': tensor(0.), 'WalkTime11': tensor(0.), 'NoT11': tensor(0.)}, '12': {'IVTT12': tensor(0.), 'PT_fare12': tensor(0.), 'WalkTime12': tensor(0.), 'NoT12': tensor(0.)}, '13': {'IVTT13': tensor(0.), 'PT_fare13': tensor(0.), 'WalkTime13': tensor(0.), 'NoT13': tensor(0.)}, '14': {'IVTT14': tensor(0.), 'PT_fare14': tensor(0.), 'WalkTime14': tensor(0.), 'NoT14': tensor(0.)}}, 'y': tensor(5), 'z': tensor([0., 0.]), 'av': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0.])}\n",
      "1 {'x': {'0': {'IVTT0': tensor(2754.), 'PT_fare0': tensor(1.3100), 'WalkTime0': tensor(320.), 'NoT0': tensor(0.)}, '1': {'IVTT1': tensor(3446.), 'PT_fare1': tensor(1.3100), 'WalkTime1': tensor(320.), 'NoT1': tensor(1.)}, '2': {'IVTT2': tensor(3472.), 'PT_fare2': tensor(1.3100), 'WalkTime2': tensor(320.), 'NoT2': tensor(1.)}, '3': {'IVTT3': tensor(3747.), 'PT_fare3': tensor(1.3100), 'WalkTime3': tensor(320.), 'NoT3': tensor(1.)}, '4': {'IVTT4': tensor(3428.), 'PT_fare4': tensor(1.3100), 'WalkTime4': tensor(320.), 'NoT4': tensor(1.)}, '5': {'IVTT5': tensor(1377.), 'PT_fare5': tensor(1.3100), 'WalkTime5': tensor(1034.), 'NoT5': tensor(0.)}, '6': {'IVTT6': tensor(2170.), 'PT_fare6': tensor(1.3800), 'WalkTime6': tensor(734.), 'NoT6': tensor(1.)}, '7': {'IVTT7': tensor(2397.), 'PT_fare7': tensor(1.3800), 'WalkTime7': tensor(705.), 'NoT7': tensor(1.)}, '8': {'IVTT8': tensor(0.), 'PT_fare8': tensor(0.), 'WalkTime8': tensor(0.), 'NoT8': tensor(0.)}, '9': {'IVTT9': tensor(0.), 'PT_fare9': tensor(0.), 'WalkTime9': tensor(0.), 'NoT9': tensor(0.)}, '10': {'IVTT10': tensor(0.), 'PT_fare10': tensor(0.), 'WalkTime10': tensor(0.), 'NoT10': tensor(0.)}, '11': {'IVTT11': tensor(0.), 'PT_fare11': tensor(0.), 'WalkTime11': tensor(0.), 'NoT11': tensor(0.)}, '12': {'IVTT12': tensor(0.), 'PT_fare12': tensor(0.), 'WalkTime12': tensor(0.), 'NoT12': tensor(0.)}, '13': {'IVTT13': tensor(0.), 'PT_fare13': tensor(0.), 'WalkTime13': tensor(0.), 'NoT13': tensor(0.)}, '14': {'IVTT14': tensor(0.), 'PT_fare14': tensor(0.), 'WalkTime14': tensor(0.), 'NoT14': tensor(0.)}}, 'y': tensor(7), 'z': tensor([0., 0.]), 'av': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0.])}\n",
      "2 {'x': {'0': {'IVTT0': tensor(32816.), 'PT_fare0': tensor(1.8000), 'WalkTime0': tensor(457.), 'NoT0': tensor(1.)}, '1': {'IVTT1': tensor(4434.), 'PT_fare1': tensor(1.8000), 'WalkTime1': tensor(457.), 'NoT1': tensor(1.)}, '2': {'IVTT2': tensor(4363.), 'PT_fare2': tensor(1.7600), 'WalkTime2': tensor(378.), 'NoT2': tensor(1.)}, '3': {'IVTT3': tensor(5059.), 'PT_fare3': tensor(1.8000), 'WalkTime3': tensor(378.), 'NoT3': tensor(1.)}, '4': {'IVTT4': tensor(4570.), 'PT_fare4': tensor(1.7600), 'WalkTime4': tensor(378.), 'NoT4': tensor(1.)}, '5': {'IVTT5': tensor(2921.), 'PT_fare5': tensor(1.6800), 'WalkTime5': tensor(425.), 'NoT5': tensor(0.)}, '6': {'IVTT6': tensor(3988.), 'PT_fare6': tensor(1.6800), 'WalkTime6': tensor(461.), 'NoT6': tensor(1.)}, '7': {'IVTT7': tensor(3952.), 'PT_fare7': tensor(1.6800), 'WalkTime7': tensor(461.), 'NoT7': tensor(1.)}, '8': {'IVTT8': tensor(4001.), 'PT_fare8': tensor(1.6800), 'WalkTime8': tensor(461.), 'NoT8': tensor(1.)}, '9': {'IVTT9': tensor(3991.), 'PT_fare9': tensor(1.6800), 'WalkTime9': tensor(461.), 'NoT9': tensor(1.)}, '10': {'IVTT10': tensor(0.), 'PT_fare10': tensor(0.), 'WalkTime10': tensor(0.), 'NoT10': tensor(0.)}, '11': {'IVTT11': tensor(0.), 'PT_fare11': tensor(0.), 'WalkTime11': tensor(0.), 'NoT11': tensor(0.)}, '12': {'IVTT12': tensor(0.), 'PT_fare12': tensor(0.), 'WalkTime12': tensor(0.), 'NoT12': tensor(0.)}, '13': {'IVTT13': tensor(0.), 'PT_fare13': tensor(0.), 'WalkTime13': tensor(0.), 'NoT13': tensor(0.)}, '14': {'IVTT14': tensor(0.), 'PT_fare14': tensor(0.), 'WalkTime14': tensor(0.), 'NoT14': tensor(0.)}}, 'y': tensor(5), 'z': tensor([0., 0.]), 'av': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0.])}\n",
      "3 {'x': {'0': {'IVTT0': tensor(6815.), 'PT_fare0': tensor(2.0500), 'WalkTime0': tensor(651.), 'NoT0': tensor(1.)}, '1': {'IVTT1': tensor(35118.), 'PT_fare1': tensor(2.0500), 'WalkTime1': tensor(314.), 'NoT1': tensor(1.)}, '2': {'IVTT2': tensor(6828.), 'PT_fare2': tensor(2.0700), 'WalkTime2': tensor(314.), 'NoT2': tensor(1.)}, '3': {'IVTT3': tensor(34980.), 'PT_fare3': tensor(2.0400), 'WalkTime3': tensor(557.), 'NoT3': tensor(1.)}, '4': {'IVTT4': tensor(6630.), 'PT_fare4': tensor(2.0500), 'WalkTime4': tensor(557.), 'NoT4': tensor(1.)}, '5': {'IVTT5': tensor(2870.), 'PT_fare5': tensor(1.7600), 'WalkTime5': tensor(379.), 'NoT5': tensor(0.)}, '6': {'IVTT6': tensor(3959.), 'PT_fare6': tensor(1.7600), 'WalkTime6': tensor(556.), 'NoT6': tensor(1.)}, '7': {'IVTT7': tensor(4250.), 'PT_fare7': tensor(1.7600), 'WalkTime7': tensor(556.), 'NoT7': tensor(1.)}, '8': {'IVTT8': tensor(4126.), 'PT_fare8': tensor(1.7600), 'WalkTime8': tensor(636.), 'NoT8': tensor(1.)}, '9': {'IVTT9': tensor(4055.), 'PT_fare9': tensor(1.7600), 'WalkTime9': tensor(636.), 'NoT9': tensor(1.)}, '10': {'IVTT10': tensor(0.), 'PT_fare10': tensor(0.), 'WalkTime10': tensor(0.), 'NoT10': tensor(0.)}, '11': {'IVTT11': tensor(0.), 'PT_fare11': tensor(0.), 'WalkTime11': tensor(0.), 'NoT11': tensor(0.)}, '12': {'IVTT12': tensor(0.), 'PT_fare12': tensor(0.), 'WalkTime12': tensor(0.), 'NoT12': tensor(0.)}, '13': {'IVTT13': tensor(0.), 'PT_fare13': tensor(0.), 'WalkTime13': tensor(0.), 'NoT13': tensor(0.)}, '14': {'IVTT14': tensor(0.), 'PT_fare14': tensor(0.), 'WalkTime14': tensor(0.), 'NoT14': tensor(0.)}}, 'y': tensor(5), 'z': tensor([0., 1.]), 'av': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0.])}\n"
     ]
    }
   ],
   "source": [
    "for index, data in enumerate(dataset):\n",
    "    print(index, data)\n",
    "    if index == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotDict(dict):\n",
    "    \"\"\"\n",
    "    A dictionary subclass that allows attribute access to its keys.\n",
    "    \"\"\"\n",
    "    def __getattr__(self, attr):\n",
    "        value = self.get(attr)\n",
    "        if isinstance(value, dict):\n",
    "            return DotDict(value)\n",
    "        return value\n",
    "\n",
    "args = DotDict({\n",
    "    'batch_size': 32,\n",
    "    'num_epochs': 100,\n",
    "    'nll_tol': 0.001,\n",
    "    'no_chg': 5,\n",
    "    'lr': 0.001,\n",
    "    'weight_decay': 0.000,\n",
    "    'transform': 'exp',\n",
    "    'l1': 0.000,\n",
    "    'l2': 0.000,\n",
    "    'taste_params': 8,\n",
    "    'K': 4,\n",
    "    'J': 3,\n",
    "    'hidden_sizes': [],\n",
    "    'act_func': '',\n",
    "    'mu': 1.0,\n",
    "    'model_no': 999,\n",
    "    'cuda': False,\n",
    "    'seed': None,\n",
    "    'data_path': '../data',\n",
    "    'result_root': '../results',\n",
    "    'layer_sizes': [ds_test.z.size()[1]]+[]+[8],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def get_act(nl_func):\n",
    "    if nl_func==\"tanh\":\n",
    "        return nn.Tanh()\n",
    "    elif nl_func == \"relu\":\n",
    "        return nn.ReLU()\n",
    "    elif nl_func == \"sigmoid\":\n",
    "        return nn.Sigmoid()\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "class ChoiceFlex(nn.Module):\n",
    "    \"\"\"TasteNet-MNL model for Swissmetro\"\"\"\n",
    "    def __init__(self, args):\n",
    "        super(ChoiceFlex, self).__init__()\n",
    "        self.params_module = TasteParams(args.layer_sizes, args)\n",
    "        self.util_module = Utility(args)\n",
    "        self.args = args\n",
    "    \n",
    "    def forward(self, z, x, av):\n",
    "        b = self.params_module(z) # taste parameters, (N,8)\n",
    "        print(\"Shape of b: \", b.shape, b)\n",
    "        b = self.constraints(b)  ## this is another way to include constraint:  using transformation to include constraints \n",
    "        print(\"Shape of b after constraints: \", b.shape, b)\n",
    "        v = self.util_module(x,b) #no softmax here \n",
    "        print(\"Shape of v: \", v.shape)\n",
    "        exp_v = torch.exp(v)\n",
    "        print(\"Shape of exp_v: \", exp_v.shape)\n",
    "        exp_v_av = exp_v * av\n",
    "        print(\"Shape of exp_v_av: \", exp_v_av.shape)\n",
    "        \n",
    "        prob = exp_v_av/exp_v_av.sum(dim=1).view(-1,1) # prob (N,J)\n",
    "        \n",
    "        return prob, None  \n",
    "    \n",
    "    def constraints(self,b):\n",
    "        '''\n",
    "            Put transformation for the sake of constraints on the value of times \n",
    "        '''\n",
    "        if self.args.transform=='relu':\n",
    "            return torch.cat([-F.relu(-b[:,:-3]),b[:,-3:]],dim=1)\n",
    "        elif self.args.transform == 'exp':\n",
    "            return torch.cat([-torch.exp(-self.args.mu * b[:,:-3]),b[:,-3:]],dim=1) # the last 3 dim of b are under constraints\n",
    "        else:\n",
    "            return b\n",
    "    \n",
    "    def getParameters(self):\n",
    "        '''\n",
    "        get coef and bias of the TasteParams of the model \n",
    "        '''\n",
    "        count = 0\n",
    "        bias = []\n",
    "        coef = []\n",
    "        for params in self.parameters():\n",
    "            if count % 2==0:\n",
    "                coef.append(params)\n",
    "            else:\n",
    "                bias.append(params)\n",
    "            count += 1\n",
    "        return coef, bias\n",
    "    \n",
    "    def L2Norm(self):\n",
    "        '''\n",
    "        L2 norm, not including bias\n",
    "        '''\n",
    "        coef, bias = self.getParameters()\n",
    "        norm = torch.zeros(1)\n",
    "        for params in coef:\n",
    "            norm += (params**2).sum()\n",
    "        return norm            \n",
    "\n",
    "    def L1Norm(self):\n",
    "        '''\n",
    "        L1 norm, not including bias\n",
    "        '''\n",
    "        coef, bias = self.getParameters()\n",
    "        norm = torch.zeros(1)\n",
    "        for params in coef:\n",
    "            norm += (torch.abs(params).sum())\n",
    "        return norm\n",
    "\n",
    "class Utility(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(Utility, self).__init__()\n",
    "        self.args = args\n",
    "        self.index = OrderedDict(zip(['TRAIN_TT', 'SM_TT', 'CAR_TT', 'TRAIN_HE', 'SM_HE', 'SM_SEATS', 'TRAIN_ASC', 'SM_ASC'], range(8)))\n",
    "\n",
    "        \n",
    "    def forward(self, x, b):\n",
    "        '''\n",
    "        x: attributes of each alternative, \n",
    "           including the intercept (N,K+1,J)  J alternatives, each have K+1 attributes including 1 for intercept. \n",
    "        b: taste parameters (K+1,J)  Some paramters are constant, some come from neural network hidden layer.  \n",
    "        '''\n",
    "        index = self.index\n",
    "        N = len(b)        \n",
    "        # last hidden nodes correspond to b_names\n",
    "        v = torch.zeros(N,3)       \n",
    "        print(\"Shape of v: \", v.shape) \n",
    "        v[:,0] = torch.ones(N) * b[:,index[\"TRAIN_ASC\"]] + x[\"TRAIN\"][\"TRAIN_TT\"]*b[:,index[\"TRAIN_TT\"]] + x[\"TRAIN\"][\"TRAIN_HE\"]*b[:,index[\"TRAIN_HE\"]] - x[\"TRAIN\"][\"TRAIN_CO\"]\n",
    "        print(\"Shape of v[:,0]: \", v[:,0].shape, v[:,0])\n",
    "        v[:,1] = torch.ones(N) * b[:,index[\"SM_ASC\"]] + x[\"SM\"][\"SM_TT\"]*b[:,index[\"SM_TT\"]] + x[\"SM\"][\"SM_HE\"]*b[:,index[\"SM_HE\"]] + x[\"SM\"][\"SM_SEATS\"]*b[:,index[\"SM_SEATS\"]] - x[\"SM\"][\"SM_CO\"]\n",
    "        print(\"Shape of v[:,1]: \", v[:,1].shape, v[:,1])\n",
    "        v[:,2] = x[\"CAR\"][\"CAR_TT\"]*b[:,index[\"CAR_TT\"]] - x[\"CAR\"][\"CAR_CO\"]\n",
    "        print(\"Shape of v[:,2]: \", v[:,2].shape, v[:,2])\n",
    "        \n",
    "        return v\n",
    "\n",
    "class TasteParams(nn.Module):\n",
    "    '''\n",
    "    Network for tastes\n",
    "    '''\n",
    "    def __init__(self, layer_sizes, args):\n",
    "        super(TasteParams, self).__init__()\n",
    "        self.seq = nn.Sequential()\n",
    "        for i, (in_size, out_size) in enumerate(zip(layer_sizes[:-1], layer_sizes[1:])):\n",
    "            self.seq.add_module(name=\"L%i\"%(i+1), module=nn.Linear(in_size, out_size, bias=True))\n",
    "            if i<len(layer_sizes)-2:\n",
    "                self.seq.add_module(name=\"A%i\"%(i+1), module=get_act(args.act_func))\n",
    "        self.args = args\n",
    "        \n",
    "    def forward(self,z):\n",
    "        '''\n",
    "        Parameters:\n",
    "            z: (N,D) # batch size, input dimension\n",
    "        Returns:\n",
    "            V: (N,K) # taste parameters \n",
    "        '''\n",
    "        N,D = z.size()\n",
    "        test = self.seq(z)\n",
    "        print(\"Shape of test: \", test.shape, test)\n",
    "        return  test# (N,K) \n",
    "\n",
    "model = ChoiceFlex(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 1., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 1., 0., 0.],\n",
      "        ...,\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]]) {'TRAIN': {'TRAIN_TT': tensor(1.1600), 'TRAIN_HE': tensor(0.3000), 'TRAIN_CO': tensor(0.3500)}, 'SM': {'SM_TT': tensor(0.7300), 'SM_HE': tensor(0.2000), 'SM_CO': tensor(0.4500), 'SM_SEATS': tensor(0.)}, 'CAR': {'CAR_TT': tensor(0.), 'CAR_CO': tensor(0.)}} tensor([[1., 1., 0.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        ...,\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "print(ds_test.z, ds_test[0]['x'], ds_test.av)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of test:  torch.Size([1604, 8]) tensor([[-0.0683,  0.0886,  0.1025,  ..., -0.0419,  0.4013, -0.2079],\n",
      "        [ 0.0255,  0.3066, -0.4723,  ..., -0.2628,  0.2486, -0.2341],\n",
      "        [-0.0694, -0.4241, -0.0321,  ...,  0.3155,  0.4547, -0.0091],\n",
      "        ...,\n",
      "        [ 0.0906,  0.0254, -0.2923,  ...,  0.2476,  0.4071, -0.0164],\n",
      "        [-0.1186, -0.1864, -0.0915,  ...,  0.2632,  0.3812,  0.1247],\n",
      "        [-0.4876,  0.4111, -0.2344,  ..., -0.2402,  0.1962, -0.0526]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Shape of b:  torch.Size([1604, 8]) tensor([[-0.0683,  0.0886,  0.1025,  ..., -0.0419,  0.4013, -0.2079],\n",
      "        [ 0.0255,  0.3066, -0.4723,  ..., -0.2628,  0.2486, -0.2341],\n",
      "        [-0.0694, -0.4241, -0.0321,  ...,  0.3155,  0.4547, -0.0091],\n",
      "        ...,\n",
      "        [ 0.0906,  0.0254, -0.2923,  ...,  0.2476,  0.4071, -0.0164],\n",
      "        [-0.1186, -0.1864, -0.0915,  ...,  0.2632,  0.3812,  0.1247],\n",
      "        [-0.4876,  0.4111, -0.2344,  ..., -0.2402,  0.1962, -0.0526]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Shape of b after constraints:  torch.Size([1604, 8]) tensor([[-1.0707, -0.9152, -0.9025,  ..., -0.0419,  0.4013, -0.2079],\n",
      "        [-0.9748, -0.7359, -1.6036,  ..., -0.2628,  0.2486, -0.2341],\n",
      "        [-1.0719, -1.5282, -1.0326,  ...,  0.3155,  0.4547, -0.0091],\n",
      "        ...,\n",
      "        [-0.9134, -0.9750, -1.3395,  ...,  0.2476,  0.4071, -0.0164],\n",
      "        [-1.1259, -1.2048, -1.0958,  ...,  0.2632,  0.3812,  0.1247],\n",
      "        [-1.6284, -0.6629, -1.2641,  ..., -0.2402,  0.1962, -0.0526]],\n",
      "       grad_fn=<CatBackward0>)\n",
      "Shape of v:  torch.Size([1604, 3])\n",
      "Shape of v[:,0]:  torch.Size([1604]) tensor([-1.3746, -1.4369, -1.2881,  ..., -1.2098, -1.5003, -2.2242],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Shape of v[:,1]:  torch.Size([1604]) tensor([-1.5553, -1.4432, -1.9460,  ..., -1.4117, -1.4976, -1.1965],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Shape of v[:,2]:  torch.Size([1604]) tensor([-0., -0., -0.,  ..., -0., -0., -0.], grad_fn=<SelectBackward0>)\n",
      "Shape of v:  torch.Size([1604, 3])\n",
      "Shape of exp_v:  torch.Size([1604, 3])\n",
      "Shape of exp_v_av:  torch.Size([1604, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0.5451, 0.4549, 0.0000],\n",
       "         [0.1613, 0.1602, 0.6785],\n",
       "         [0.1944, 0.1007, 0.7049],\n",
       "         ...,\n",
       "         [0.1934, 0.1581, 0.6485],\n",
       "         [0.4993, 0.5007, 0.0000],\n",
       "         [0.0767, 0.2143, 0.7090]], grad_fn=<DivBackward0>),\n",
       " None)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(ds_test.z, ds_test[0]['x'], ds_test.av)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
